{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1\n",
      "Accuracy :  90.8547619047619\n",
      "Epoch :  2\n",
      "Accuracy :  92.0\n",
      "Epoch :  3\n",
      "Accuracy :  91.99761904761905\n",
      "Epoch :  4\n",
      "Accuracy :  92.93333333333334\n",
      "Epoch :  5\n",
      "Accuracy :  93.20714285714286\n",
      "Epoch :  6\n",
      "Accuracy :  93.81904761904762\n",
      "Epoch :  7\n",
      "Accuracy :  93.94761904761904\n",
      "Epoch :  8\n",
      "Accuracy :  93.78571428571428\n",
      "Epoch :  9\n",
      "Accuracy :  93.8952380952381\n",
      "Epoch :  10\n",
      "Accuracy :  93.78571428571428\n",
      "Epoch :  11\n",
      "Accuracy :  94.72142857142856\n",
      "Epoch :  12\n",
      "Accuracy :  95.02142857142857\n"
     ]
    }
   ],
   "source": [
    "## importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def accuracy():\n",
    "    ## this function tells accuaracy of the current model on training set.\n",
    "    count = 0\n",
    "    for i in range(m):\n",
    "        xx = x[:,i]\n",
    "        yy = y[:,i]\n",
    "        prediction_array = net.feedforward(xx.reshape(784,1))\n",
    "        ind = np.argmax(prediction_array)\n",
    "        if(ind == yy):\n",
    "            count +=1\n",
    "    print(\"Accuracy : \",(count/m)*100)\n",
    "\n",
    "\n",
    "## importing data_frame from the CSV file.\n",
    "data_frame = pd.read_csv(r'C:\\Users\\Anant Agarwal\\Desktop\\Machine Learning\\Codes\\8 - FeedForward Neural Network\\train_set_full_shuffled.csv')\n",
    "x = data_frame.iloc[:,1:].values ## shape is (m,n) \n",
    "y = data_frame.iloc[:,0].values  ## shape is (m,1) \n",
    "\n",
    "## number of examples\n",
    "m = x.shape[0]                  \n",
    "epochs = 12\n",
    "\n",
    "## learning_rate\n",
    "alpha = .5\n",
    "x = x.T                          ## shape is (n,m) \n",
    "x = x/255                        ## normalizing the data\n",
    "y = y.reshape(-1,1)\n",
    "y = y.T                          ## shape is (1,m) \n",
    "\n",
    "## stochastic gradient descent\n",
    "batch_size = 1\n",
    "\n",
    "## defining sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "## definining sigmoid gradient function \"sigmoid prime\"\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "class Network(object):\n",
    "    ## class constructor\n",
    "    def __init__(self,sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        np.random.seed(5)\n",
    "        self.biases = [np.random.randn(y,1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y,x) for x,y in zip(sizes[:-1],sizes[1:])]\n",
    "    \n",
    "    \n",
    "    ## feedforward function\n",
    "    def feedforward(self, a):\n",
    "        for b,w in zip(self.biases,self.weights):\n",
    "            a = sigmoid(np.dot(w,a) +b)\n",
    "        return a\n",
    "    \n",
    "    ## Applying Mini_Batch Gradient Descent\n",
    "    def gradient_descent(self,x,y,epochs,alpha):\n",
    "        for j in range(epochs):\n",
    "            print(\"Epoch : \", j+1)\n",
    "            ## real_batch_size is a variable defined to take care of the unsurity of the\n",
    "            ## size of the last batch.\n",
    "            real_batch_size = batch_size\n",
    "            ## loop for distributing batches\n",
    "            for i in range(0,m,batch_size):\n",
    "                ## xx and yy contains x's and y's for a particular batch\n",
    "                xx, yy = x[:,i : (i+batch_size)], y[:,i : (i+batch_size)]\n",
    "                \n",
    "                ## initialization of weights and biases for a single batch\n",
    "                nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "                nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "                \n",
    "                ## implementation detail\n",
    "                if(m-i<batch_size):\n",
    "                    real_batch_size = m-i\n",
    "                \n",
    "                ## for each example, calculating the delta values and keeping it in the nabla variable\n",
    "                for kk in range(real_batch_size):\n",
    "                     ## finding out delta values by calling the backpropagation function\n",
    "                    delta_nabla_b, delta_nabla_w = self.backprop(xx[:,kk],yy[:,kk])\n",
    "                    \n",
    "                    ## adding the delta_nabla values to nabla variables\n",
    "                    nabla_b = [nb+dnb for nb,dnb in zip(nabla_b,delta_nabla_b)]\n",
    "                    nabla_w = [nw+dnw for nw,dnw in zip(nabla_w,delta_nabla_w)]\n",
    "                \n",
    "                ## after each batch using the nabla values to change the weights\n",
    "                self.weights = [w-(alpha/batch_size)*nw for w,nw in zip(self.weights, delta_nabla_w)]\n",
    "                self.biases = [b-(alpha/batch_size)*nb for b,nb in zip(self.biases, delta_nabla_b)]\n",
    "                \n",
    "            ## calling out accuracy() function after each epoch to make sure our model is really working\n",
    "            accuracy()\n",
    "            \n",
    "    def backprop(self,x,y):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        ## feedforward propagation\n",
    "        x = x.reshape(-1,1)\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        \n",
    "        for b,w in zip(self.biases,self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "            \n",
    "        ## backward propagation\n",
    "        delta = self.cost_derivative(activations[-1], y)*sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].T)\n",
    "        \n",
    "        for layer in range(2, self.num_layers):\n",
    "            delta = np.dot(self.weights[-layer+1].transpose(), delta) * sigmoid_prime(zs[-layer])\n",
    "            nabla_b[-layer] = delta\n",
    "            nabla_w[-layer] = np.dot(delta, activations[-layer-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "    \n",
    "    ## derivative of the cost function\n",
    "    def cost_derivative(self,output_activations,y):\n",
    "        target = np.zeros((10,1))\n",
    "        target[y] = 1\n",
    "        return 2*(output_activations - target)\n",
    "        \n",
    "## making a neural net with one hidden layer with 30 neurons    \n",
    "net = Network([784,30,10])\n",
    "## calling gradient descent to start the training process\n",
    "net.gradient_descent(x,y,epochs,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calling this code will generate predictions for the images in the test set which we'll eventually store in a CSV file.\n",
    "\n",
    "test_set = pd.read_csv(r'C:\\Users\\Anant Agarwal\\Desktop\\Machine Learning\\Kaggle\\MNIST\\Data\\test.csv')\n",
    "x_test = test_set.values ## shape is (m,n) i.e. (28000,784)\n",
    "x_test = x_test/255\n",
    "m_test = x_test.shape[0]\n",
    "arr = []\n",
    "\n",
    "for i in range(m_test):\n",
    "    xxx = x_test[i,:].reshape(-1,1)\n",
    "    result = np.argmax(net.feedforward(xxx))\n",
    "    arr.append(result)\n",
    "\n",
    "## making a dataframe\n",
    "ddf = pd.DataFrame({'ImageId':[i+1 for i in range(m_test)],'label':arr})\n",
    "## saving that dataframe as a CSV file\n",
    "ddf.to_csv(r'C:\\Users\\Anant Agarwal\\Desktop\\Machine Learning\\Codes\\8 - FeedForward Neural Network\\kagle_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
